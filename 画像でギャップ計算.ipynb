{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "画像でギャップ計算.ipynb",
      "provenance": [],
      "mount_file_id": "1KE5WyHktSsuIlMkfolDPWrBUgCpmON5v",
      "authorship_tag": "ABX9TyMwhwhkA6khZ0ZstwFJMl5B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sollall/myidea/blob/sisaku/%E7%94%BB%E5%83%8F%E3%81%A7%E3%82%AE%E3%83%A3%E3%83%83%E3%83%97%E8%A8%88%E7%AE%97.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zTTV-teUbwl"
      },
      "source": [
        "!pip install condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "\n",
        "!mamba install -c conda-forge rdkit\n",
        "\n",
        "from google.colab import output\n",
        "output.clear()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv7gF5wa6Aem",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "190d8e43-fbf9-49bc-a191-5a453f44f0f4"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK9Ocf8W-vk3",
        "outputId": "6f84f55e-80f8-4170-bc8a-584e79aad00e"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/qm9.csv\")\n",
        "x=list(df[\"smiles\"])\n",
        "y=list(df[\"gap\"])\n",
        "\n",
        "x=np.asarray(x)\n",
        "y=np.asarray(y)\n",
        "y=(y-min(y))/(max(y)-min(y))\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y,train_size=0.8)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xybnF-_Nox-d",
        "outputId": "2b5e1c4a-9a13-418c-cadf-3f802cf920b3"
      },
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "def smiles2input(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    Draw.MolToFile(mol,\"temp.png\",size=(32,32))\n",
        "    temp=np.array(Image.open(\"temp.png\"))\n",
        "    #Draw.MolToFile(mol,\"test.png\")\n",
        "\n",
        "    temp=np.float32(temp)\n",
        "\n",
        "    for i in range(len(temp)):\n",
        "        for j in range(len(temp[i])):\n",
        "            temp[i][j]=1-(temp[i][j]/255)\n",
        "    temp/=3\n",
        "\n",
        "    res=[[] for i in range(len(temp))]\n",
        "    \n",
        "    for i in range(len(temp)):\n",
        "        for j in range(len(temp[i])):\n",
        "            res[i].append(np.sum(temp[i][j],axis=0))\n",
        "    \n",
        "    res=np.array([[res]])\n",
        "    res=torch.tensor(res)\n",
        "    return res\n",
        "\n",
        "smiles2input('CC(C)CC')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2nFLSkuV0Oa",
        "outputId": "8e21bfbd-7348-4b8f-e127-87dbd57bc24c"
      },
      "source": [
        "torch.randn(1,1,300,300)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 2.4929,  0.8089, -0.4785,  ...,  0.5998, -0.9241,  1.3257],\n",
              "          [-1.4561,  0.5671,  1.3573,  ...,  1.9645, -0.5374,  0.2269],\n",
              "          [-2.4749, -0.8211, -0.4525,  ..., -0.1409,  1.2456, -0.4027],\n",
              "          ...,\n",
              "          [-0.2278, -0.7657,  0.4524,  ...,  0.4807,  0.2158,  0.2279],\n",
              "          [ 2.0445, -0.3120,  3.1239,  ..., -1.6728, -1.2091,  0.7550],\n",
              "          [-0.2529, -0.0704, -0.3758,  ...,  0.3289,  2.0847, -0.8232]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSF-VKoVjo4a",
        "outputId": "c46e89e5-8317-4823-bb88-4a1d42e5807d"
      },
      "source": [
        "net(smiles2input('CC(C)CC'))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0406,  0.0122,  0.0161,  0.0882, -0.0961, -0.0800, -0.0360, -0.0126,\n",
              "          0.0343,  0.0574]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcA3EUMgBww7",
        "outputId": "2f4bc7b4-10bb-430b-9644-89932b9f7b62"
      },
      "source": [
        "net(torch.randn(1, 1, 32, 32))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0626,  0.0100,  0.0151,  0.0745, -0.0429, -0.0714, -0.0259, -0.0117,\n",
              "          0.0153,  0.0288]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IxTUy9iRegH",
        "outputId": "21184ea6-9474-4dfe-9376-e05c08056a23"
      },
      "source": [
        "target = torch.randn(10)  # a dummy target, for example\n",
        "print(target)\n",
        "target = target.view(1, -1)  # make it the same shape as output\n",
        "print(target)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.2994,  2.3114, -0.3772, -0.1755,  1.1682,  0.9018,  0.2545, -0.7810,\n",
            "        -1.2781,  0.4275])\n",
            "tensor([[ 0.2994,  2.3114, -0.3772, -0.1755,  1.1682,  0.9018,  0.2545, -0.7810,\n",
            "         -1.2781,  0.4275]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08cQaJgp-1Go",
        "outputId": "e8e1d283-2085-475a-8fee-c7d8f7867d42"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# create your optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "steps=5\n",
        "loss=float(\"inf\")\n",
        "for step in range(steps):\n",
        "    \n",
        "    print(str(step+1)+\"/\"+str(steps))\n",
        "    for index in range(len(x_train)):\n",
        "        optimizer.zero_grad()\n",
        "        output=net(smiles2input(x_train[index]))\n",
        "        target=np.float(np.asarray(y_train[index]))\n",
        "        target=torch.tensor(target)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if index%(len(x_train)//10)==0:\n",
        "            print(\"　\"+str(index)+\"/\"+str(len(x_train)))\n",
        "            print(\"　\"+str(loss))\n",
        "    \n",
        "\n",
        "\n",
        "    \n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/5\n",
            "　0/107108\n",
            "　tensor(5.6495e-05, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "　10710/107108\n",
            "　tensor(0.0139, grad_fn=<MseLossBackward>)\n",
            "　21420/107108\n",
            "　tensor(0.0023, grad_fn=<MseLossBackward>)\n",
            "　32130/107108\n",
            "　tensor(0.0091, grad_fn=<MseLossBackward>)\n",
            "　42840/107108\n",
            "　tensor(0.0126, grad_fn=<MseLossBackward>)\n",
            "　53550/107108\n",
            "　tensor(0.0009, grad_fn=<MseLossBackward>)\n",
            "　64260/107108\n",
            "　tensor(0.0040, grad_fn=<MseLossBackward>)\n",
            "　74970/107108\n",
            "　tensor(0.0134, grad_fn=<MseLossBackward>)\n",
            "　85680/107108\n",
            "　tensor(0.0026, grad_fn=<MseLossBackward>)\n",
            "　96390/107108\n",
            "　tensor(0.0028, grad_fn=<MseLossBackward>)\n",
            "　107100/107108\n",
            "　tensor(0.0003, grad_fn=<MseLossBackward>)\n",
            "2/5\n",
            "　0/107108\n",
            "　tensor(2.6015e-05, grad_fn=<MseLossBackward>)\n",
            "　10710/107108\n",
            "　tensor(0.0100, grad_fn=<MseLossBackward>)\n",
            "　21420/107108\n",
            "　tensor(0.0005, grad_fn=<MseLossBackward>)\n",
            "　32130/107108\n",
            "　tensor(0.0056, grad_fn=<MseLossBackward>)\n",
            "　42840/107108\n",
            "　tensor(0.0017, grad_fn=<MseLossBackward>)\n",
            "　53550/107108\n",
            "　tensor(0.0006, grad_fn=<MseLossBackward>)\n",
            "　64260/107108\n",
            "　tensor(0.0023, grad_fn=<MseLossBackward>)\n",
            "　74970/107108\n",
            "　tensor(0.0093, grad_fn=<MseLossBackward>)\n",
            "　85680/107108\n",
            "　tensor(0.0068, grad_fn=<MseLossBackward>)\n",
            "　96390/107108\n",
            "　tensor(0.0014, grad_fn=<MseLossBackward>)\n",
            "　107100/107108\n",
            "　tensor(0.0003, grad_fn=<MseLossBackward>)\n",
            "3/5\n",
            "　0/107108\n",
            "　tensor(7.6901e-05, grad_fn=<MseLossBackward>)\n",
            "　10710/107108\n",
            "　tensor(0.0061, grad_fn=<MseLossBackward>)\n",
            "　21420/107108\n",
            "　tensor(0.0006, grad_fn=<MseLossBackward>)\n",
            "　32130/107108\n",
            "　tensor(0.0054, grad_fn=<MseLossBackward>)\n",
            "　42840/107108\n",
            "　tensor(0.0014, grad_fn=<MseLossBackward>)\n",
            "　53550/107108\n",
            "　tensor(0.0027, grad_fn=<MseLossBackward>)\n",
            "　64260/107108\n",
            "　tensor(0.0019, grad_fn=<MseLossBackward>)\n",
            "　74970/107108\n",
            "　tensor(0.0066, grad_fn=<MseLossBackward>)\n",
            "　85680/107108\n",
            "　tensor(0.0117, grad_fn=<MseLossBackward>)\n",
            "　96390/107108\n",
            "　tensor(0.0015, grad_fn=<MseLossBackward>)\n",
            "　107100/107108\n",
            "　tensor(0.0005, grad_fn=<MseLossBackward>)\n",
            "4/5\n",
            "　0/107108\n",
            "　tensor(0.0005, grad_fn=<MseLossBackward>)\n",
            "　10710/107108\n",
            "　tensor(0.0058, grad_fn=<MseLossBackward>)\n",
            "　21420/107108\n",
            "　tensor(0.0004, grad_fn=<MseLossBackward>)\n",
            "　32130/107108\n",
            "　tensor(0.0059, grad_fn=<MseLossBackward>)\n",
            "　42840/107108\n",
            "　tensor(0.0017, grad_fn=<MseLossBackward>)\n",
            "　53550/107108\n",
            "　tensor(0.0056, grad_fn=<MseLossBackward>)\n",
            "　64260/107108\n",
            "　tensor(0.0019, grad_fn=<MseLossBackward>)\n",
            "　74970/107108\n",
            "　tensor(0.0048, grad_fn=<MseLossBackward>)\n",
            "　85680/107108\n",
            "　tensor(0.0116, grad_fn=<MseLossBackward>)\n",
            "　96390/107108\n",
            "　tensor(0.0009, grad_fn=<MseLossBackward>)\n",
            "　107100/107108\n",
            "　tensor(0.0009, grad_fn=<MseLossBackward>)\n",
            "5/5\n",
            "　0/107108\n",
            "　tensor(0.0006, grad_fn=<MseLossBackward>)\n",
            "　10710/107108\n",
            "　tensor(0.0070, grad_fn=<MseLossBackward>)\n",
            "　21420/107108\n",
            "　tensor(0.0005, grad_fn=<MseLossBackward>)\n",
            "　32130/107108\n",
            "　tensor(0.0060, grad_fn=<MseLossBackward>)\n",
            "　42840/107108\n",
            "　tensor(0.0013, grad_fn=<MseLossBackward>)\n",
            "　53550/107108\n",
            "　tensor(0.0081, grad_fn=<MseLossBackward>)\n",
            "　64260/107108\n",
            "　tensor(0.0017, grad_fn=<MseLossBackward>)\n",
            "　74970/107108\n",
            "　tensor(0.0036, grad_fn=<MseLossBackward>)\n",
            "　85680/107108\n",
            "　tensor(0.0112, grad_fn=<MseLossBackward>)\n",
            "　96390/107108\n",
            "　tensor(0.0005, grad_fn=<MseLossBackward>)\n",
            "　107100/107108\n",
            "　tensor(0.0010, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEBRW3lMLMKD",
        "outputId": "b5dee009-20aa-44ff-8f47-f3beb70acc9b"
      },
      "source": [
        "torch.randn(1)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0793])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    }
  ]
}